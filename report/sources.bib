@inproceedings{LibAFL,
  author    = {Fioraldi, Andrea and Maier, Dominik Christian and Zhang, Dongjia and Balzarotti, Davide},
  title     = {{LibAFL: A Framework to Build Modular and Reusable Fuzzers}},
  year      = {2022},
  isbn      = {9781450394505},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3548606.3560602},
  doi       = {10.1145/3548606.3560602},
  abstract  = {The release of AFL marked an important milestone in the area of software security testing, revitalizing fuzzing as a major research topic and spurring a large number of research studies that attempted to improve and evaluate the different aspects of the fuzzing pipeline.Many of these studies implemented their techniques by forking the AFL codebase. While this choice might seem appropriate at first, combining multiple forks into a single fuzzer requires a high engineering overhead, which hinders progress in the area and prevents fair and objective evaluations of different techniques. The highly fragmented landscape of the fuzzing ecosystem also prevents researchers from combining orthogonal techniques and makes it difficult for end users to adopt new prototype solutions.To tackle this problem, in this paper we propose LibAFL, a framework to build modular and reusable fuzzers. We discuss the different components generally used in fuzzing and map them to an extensible framework. LibAFL allows researchers and engineers to extend the core fuzzer pipeline and share their new components for further evaluations. As part of LibAFL, we integrated techniques from more than 20 previous works and conduct extensive experiments to show the benefit of our framework to combine and evaluate different approaches. We hope this can help to shed light on current advancements in fuzzing and provide a solid base for comparative and extensible research in the future.},
  booktitle = {{Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security}},
  pages     = {1051–1065},
  numpages  = {15},
  keywords  = {framework, fuzz testing, fuzzing},
  location  = {Los Angeles, CA, USA},
  series    = {CCS '22}
}

@online{LibAFLBook,
  title   = {{The LibAFL Fuzzing Library}},
  author  = {Fioraldi, Andrea and Maier, Dominik},
  url     = {https://aflplus.plus/libafl-book/},
  urldate = {2024-05-28}
}

@online{AFL,
  title   = {{Fuzzing}},
  author  = {Moroz, Max},
  date    = {2021-06-08},
  url     = {https://github.com/google/AFL},
  urldate = {2024-05-21}
}

@online{AFLCoreutils,
  title   = {{Fuzzing}},
  author  = {Sjöbom, Anders and Hasselberg, Adam},
  date    = {2019-04-25},
  url     = {https://github.com/adamhass/fuzzing/},
  urldate = {2024-05-21}
}

@misc{FileUtilsAnnouncement,
  author       = {MacKenzie, David J. },
  title        = {{GNU file utilities release 1.0}},
  howpublished = {Email to gnu.utils.bug Email List},
  date         = {1990-02-08},
  url          = {https://groups.google.com/g/gnu.utils.bug/c/CviP42X_hCY/m/YssXFn-JrX4J},
  urldate      = {2024-05-22}
}

@misc{TextUtilsAnnouncement,
  author       = {MacKenzie, David J. },
  title        = {{new GNU file and text utilities released}},
  howpublished = {Email to gnu.utils.bug Email List},
  date         = {1991-07-15},
  url          = {https://groups.google.com/g/gnu.utils.bug/c/iN5KuoJYRhU/m/V_6oiBAWF0EJ},
  urldate      = {2024-05-22}
}

@misc{ShellUtilsAnnouncement,
  author       = {MacKenzie, David J. },
  title        = {{GNU shell programming utilities released}},
  howpublished = {Email to gnu.utils.bug Email List},
  date         = {1991-08-22},
  url          = {https://groups.google.com/g/gnu.utils.bug/c/xpTRtuFpNQc/m/mRc_7JWZ0BYJ},
  urldate      = {2024-05-22}
}

@misc{CoreUtilsAnnouncement,
  author       = {Meyering, Jim},
  title        = {{package renamed to coreutils}},
  howpublished = {git commit},
  date         = {2003-01-13},
  url          = {https://git.savannah.gnu.org/cgit/coreutils.git/tree/README-package-renamed-to-coreutils},
  urldate      = {2024-05-22}
}

@online{CoreUtilsHomepage,
  title   = {{Coreutils - GNU core utilities}},
  author  = {Meyering, Jim and Brady, Pádraig and Voelker, Bernhard and Blake, Eric and Eggert, Paul and Gordon, Assaf},
  date    = {2020-12-23},
  url     = {https://www.gnu.org/software/coreutils/coreutils.html},
  urldate = {2024-05-22}
}

@online{Autoconf,
  title   = {{Autoconf}},
  author  = {Meyering, Jim},
  date    = {2020-12-08},
  url     = {https://www.gnu.org/software/autoconf},
  urldate = {2024-05-24}
}
@online{Automake,
  title   = {{Automake}},
  author  = {Meyering, Jim},
  date    = {2022-01-31},
  url     = {https://www.gnu.org/software/automake},
  urldate = {2024-05-24}
}

@online{GNULinux,
  title   = {{Linux and the GNU System}},
  author  = {Stallman, Richard},
  date    = {2021-11-02},
  url     = {https://www.gnu.org/gnu/linux-and-gnu.en.html},
  urldate = {2024-05-22}
}

@misc{GNUCoreUtils9.5,
  title        = {{GNU coreutils 9.5}},
  author       = {Meyering, Jim and Brady, Pádraig and Voelker, Bernhard and Blake, Eric and Eggert, Paul and Gordon, Assaf},
  url          = {https://ftp.gnu.org/gnu/coreutils/coreutils-9.5.tar.gz},
  howpublished = {Software Release},
  date         = {2024-03-28},
  urldate      = {2024-05-22}
}

@online{BusyBox,
  title   = {{BusyBox: The Swiss Army Knife of Embedded Linux}},
  url     = {https://www.busybox.net/about.html},
  urldate = {2024-05-22}
}

@online{Alpine,
  title   = {{Alpine Linux — About}},
  url     = {https://alpinelinux.org/about/},
  urldate = {2024-05-22}
}

@online{Uutils,
  title   = {{uutils}},
  url     = {https://uutils.github.io/},
  urldate = {2024-05-22}
}

@online{UutilsCoreUtils,
  title   = {{uutils — coreutils}},
  url     = {https://uutils.github.io/coreutils},
  urldate = {2024-05-22}
}
@online{SanitizerCoverage,
  title   = {{SanitizerCoverage}},
  url     = {https://clang.llvm.org/docs/SanitizerCoverage.html},
  urldate = {2024-05-28}
}

@article{UNIX,
  author     = {Miller, Barton P. and Fredriksen, Lars and So, Bryan},
  title      = {{An Empirical Study of the Reliability of UNIX Utilities}},
  year       = {1990},
  issue_date = {Dec. 1990},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {33},
  number     = {12},
  issn       = {0001-0782},
  url        = {https://doi.org/10.1145/96267.96279},
  doi        = {10.1145/96267.96279},
  abstract   = {The following section describes the tools we built to test the utilities. These tools include the fuzz (random character) generator, ptyjig (to test interactive utilities), and scripts to automate the testing process. Next, we will describe the tests we performed, giving the types of input we presented to the utilities. Results from the tests will follow along with an analysis of the results, including identification and classification of the program bugs that caused the crashes. The final section presents concluding remarks, including suggestions for avoiding the types of problems detected by our study and some commentary on the bugs we found. We include an Appendix with the user manual pages for fuzz and ptyjig.},
  journal    = {Commun. ACM},
  month      = {12},
  pages      = {32–44},
  numpages   = {13}
}

@unpublished{EVA,
  author = {Valentin Huber},
  title  = {{Challenges and Mitigation Strategies in Symbolic Execution Based Fuzzing Through the Lens of Survey Papers}},
  year   = {2023},
  month  = {12},
  day    = {15},
  url    = {https://github.com/riesentoaster/review-symbolic-execution-in-fuzzing/releases/download/v1.0/Huber-Valentin-Challenges-and-Mitigation-Strategies-in-Symbolic-Execution-Based-Fuzzing-Through-the-Lens-of-Survey-Papers.pdf}
}

@unpublished{VT1,
  author = {Valentin Huber},
  title  = {{Running KLEE on GNU coreutils}},
  year   = {2024},
  month  = {02},
  day    = {13},
  url    = {https://github.com/riesentoaster/klee-coreutils-experiments/releases/download/v1.0/Huber-Valentin-running-KLEE-on-coreutils-report.pdf}
}

@article{AFLFast,
  author   = {Böhme, Marcel and Pham, Van-Thuan and Roychoudhury, Abhik},
  journal  = {IEEE Transactions on Software Engineering},
  title    = {Coverage-Based Greybox Fuzzing as Markov Chain},
  year     = {2019},
  volume   = {45},
  number   = {5},
  pages    = {489-506},
  keywords = {Schedules;Markov processes;Computer crashes;Search problems;Tools;Systematics;Vulnerability detection;fuzzing;path exploration;symbolic execution;automated testing},
  doi      = {10.1109/TSE.2017.2785841}
}

@inproceedings{MOPT,
  author    = {Chenyang Lyu and Shouling Ji and Chao Zhang and Yuwei Li and Wei-Han Lee and Yu Song and Raheem Beyah},
  title     = {{MOPT}: Optimized Mutation Scheduling for Fuzzers},
  booktitle = {28th USENIX Security Symposium (USENIX Security 19)},
  year      = {2019},
  isbn      = {978-1-939133-06-9},
  address   = {Santa Clara, CA},
  pages     = {1949--1966},
  url       = {https://www.usenix.org/conference/usenixsecurity19/presentation/lyu},
  publisher = {USENIX Association},
  month     = aug
}


@article{Demystifying,
  author     = {Mallissery, Sanoop and Wu, Yu-Sung},
  title      = {Demystify the Fuzzing Methods: A Comprehensive Survey},
  year       = {2023},
  issue_date = {March 2024},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {56},
  number     = {3},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/3623375},
  doi        = {10.1145/3623375},
  abstract   = {Massive software applications possess complex data structures or parse complex data structures; in such cases, vulnerabilities in the software become inevitable. The vulnerabilities are the source of cyber-security threats, and discovering this before the software deployment is challenging. Fuzzing is a vulnerability discovery solution that resonates with random-mutation, feedback-driven, coverage-guided, constraint-guided, seed-scheduling, and target-oriented strategies. Each technique is wrapped beneath the black-, white-, and grey-box fuzzers to uncover diverse vulnerabilities. It consists of methods such as identifying structural information about the test cases to detect security vulnerabilities, symbolic and concrete program states to explore the unexplored locations, and full semantics of code coverage to create new test cases. We methodically examine each kind of fuzzers and contemporary fuzzers with a profound observation that addresses various research questions and systematically reviews and analyze the gaps and their solutions. Our survey comprised the recent related works on fuzzing techniques to demystify the fuzzing methods concerning the application domains and the target that, in turn, achieves higher code coverage and sound vulnerability detection.},
  journal    = {ACM Comput. Surv.},
  month      = {10},
  articleno  = {71},
  numpages   = {38},
  keywords   = {vulnerability discovery, Automated testing, fuzzing, code inspection}
}

@article{SurveyRoadmap,
  author     = {Zhu, Xiaogang and Wen, Sheng and Camtepe, Seyit and Xiang, Yang},
  title      = {Fuzzing: A Survey for Roadmap},
  year       = {2022},
  issue_date = {January 2022},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {54},
  number     = {11s},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/3512345},
  doi        = {10.1145/3512345},
  abstract   = {Fuzz testing (fuzzing) has witnessed its prosperity in detecting security flaws recently. It generates a large number of test cases and monitors the executions for defects. Fuzzing has detected thousands of bugs and vulnerabilities in various applications. Although effective, there lacks systematic analysis of gaps faced by fuzzing. As a technique of defect detection, fuzzing is required to narrow down the gaps between the entire input space and the defect space. Without limitation on the generated inputs, the input space is infinite. However, defects are sparse in an application, which indicates that the defect space is much smaller than the entire input space. Besides, because fuzzing generates numerous test cases to repeatedly examine targets, it requires fuzzing to perform in an automatic manner. Due to the complexity of applications and defects, it is challenging to automatize the execution of diverse applications. In this article, we systematically review and analyze the gaps as well as their solutions, considering both breadth and depth. This survey can be a roadmap for both beginners and advanced developers to better understand fuzzing.},
  journal    = {ACM Comput. Surv.},
  month      = {09},
  articleno  = {230},
  numpages   = {36},
  keywords   = {automation, input space, fuzzing theory, security, Fuzz testing}
}

@online{AFLBugs,
  title   = {{The bug-o-rama trophy case}},
  author  = {Zalewski, Michal},
  url     = {https://lcamtuf.coredump.cx/afl/#bugs},
  urldate = {2024-06-03}
}

@online{AFLPlusPlus,
  title   = {{AFL++}},
  url     = {https://aflplus.plus},
  urldate = {2024-06-03}
}

@article{UNIXRevisited,
  author   = {Miller, Barton P. and Zhang, Mengxiao and Heymann, Elisa R.},
  journal  = {IEEE Transactions on Software Engineering},
  title    = {The Relevance of Classic Fuzz Testing: Have We Solved This One?},
  year     = {2022},
  volume   = {48},
  number   = {6},
  pages    = {2028-2039},
  keywords = {Tools;Testing;Software;Operating systems;Fuzzing;Software reliability;Linux;Testing and debugging;testing tools},
  doi      = {10.1109/TSE.2020.3047766}
}

@inproceedings{CLIFuzzer,
  author    = {Gupta, Abhilash and Gopinath, Rahul and Zeller, Andreas},
  title     = {CLIFuzzer: mining grammars for command-line invocations},
  year      = {2022},
  isbn      = {9781450394130},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3540250.3558918},
  doi       = {10.1145/3540250.3558918},
  abstract  = {The behavior of command-line utilities can be very much influenced by passing command-line options and arguments—configuration 
               settings that enable, disable, or otherwise influence parts of the code to be executed. Hence, systematic testing of command-line utilities requires testing them with diverse configurations of supported command-line options. 
               
               We introduce CLIFuzzer, a tool that takes an executable program and, using dynamic analysis to track input processing, automatically 
               extract a full set of its options, arguments, and argument types. This set forms a grammar that represents the valid sequences of valid 
               options and arguments. Producing invocations from this grammar, we can fuzz the program with an endless list of random configurations, covering the related code. This leads to increased coverage and new bugs over purely mutation based fuzzers.},
  booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages     = {1667–1671},
  numpages  = {5},
  keywords  = {CLI Options, command-line, fuzzing, utilities},
  location  = {<conf-loc>, <city>Singapore</city>, <country>Singapore</country>, </conf-loc>},
  series    = {ESEC/FSE 2022}
}

@online{AFLPlusPlusargv,
  title   = {{Struggling to give inputs to AFL}},
  author  = {Zalewski, Michal},
  url     = {https://groups.google.com/g/afl-users/c/ZBWq0LdHBzw/m/zBlo7q9LBAAJ},
  urldate = {2024-06-04}
}
@inproceedings{SEDiff,
  author    = {Li, Penghui and Meng, Wei and Lu, Kangjie},
  title     = {SEDiff: scope-aware differential fuzzing to test internal function models in symbolic execution},
  year      = {2022},
  isbn      = {9781450394130},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3540250.3549080},
  doi       = {10.1145/3540250.3549080},
  abstract  = {Symbolic execution has become a foundational program analysis technique.  
               Performing symbolic execution unavoidably encounters internal functions (e.g., library functions) that provide basic operations such as string processing.  
               Many symbolic execution engines construct internal function models that abstract function behaviors for scalability and compatibility concerns.  
               Due to the high complexity of constructing the models,  
               developers intentionally summarize only partial behaviors of a function, namely modeled functionalities, in the models.  
               The correctness of the internal function models is critical because  
               it would impact all applications of symbolic execution, e.g., bug detection and model checking.  
               
               A naive solution to testing the correctness of internal function models is to cross-check whether the behaviors of the models comply with their corresponding original function implementations.  
               However, such a solution would mostly detect overwhelming inconsistencies concerning the unmodeled functionalities, which are out of the scope of models and thus considered false reports.  
               We argue that a reasonable testing approach should target only the functionalities that developers intend to model.  
               While being necessary, automatically identifying the modeled functionalities, i.e., the scope, is a significant challenge.  
               
               In this paper, we propose a scope-aware differential testing framework, SEDiff, to tackle this problem.  
               We design a novel algorithm to automatically map the modeled functionalities to the code in the original implementations.  
               SEDiff then applies scope-aware grey-box differential fuzzing to relevant code in the original implementations.  
               It also equips a new scope-aware input generator and a tailored bug checker that efficiently and correctly detect erroneous inconsistencies.  
               We extensively evaluated SEDiff on several popular real-world symbolic execution engines targeting binary, web and kernel.  
               Our manual investigation shows that SEDiff precisely identifies the modeled functionalities and detects  
               46 new bugs in the internal function models used in the symbolic execution engines.},
  booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages     = {57–69},
  numpages  = {13},
  keywords  = {Symbolic Execution, Internal Function Models, Differential Testing},
  location  = {<conf-loc>, <city>Singapore</city>, <country>Singapore</country>, </conf-loc>},
  series    = {ESEC/FSE 2022}
}

@mastersthesis{DarpaExtended,
  author = {Kilmer, Eric David},
  school = {Penn State University},
  title  = {Extending Vulnerability Discovery with Fuzzing and Symbolic Execution to Realistic Applications},
  date   = {2017-06-09}
}
@conference{Seccomp,
  author       = {Marcus Gelderie. and Valentin Barth. and Maximilian Luff. and Julian Birami.},
  title        = {Seccomp Filters from Fuzzing},
  booktitle    = {Proceedings of the 19th International Conference on Security and Cryptography - SECRYPT},
  year         = {2022},
  pages        = {507-512},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0011145100003283},
  isbn         = {978-989-758-590-6},
  issn         = {2184-7711}
}

@inproceedings{FUSE,
  author    = {Zhang, Guofeng and Chen, Zhenbang and Shuai, Ziqi and Zhang, Yufeng and Wang, Ji},
  booktitle = {2022 29th Asia-Pacific Software Engineering Conference (APSEC)},
  title     = {Synergizing Symbolic Execution and Fuzzing By Function-level Selective Symbolization},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {328-337},
  keywords  = {Codes;Fuses;Source coding;Semantics;Fuzzing;Benchmark testing;Libraries;Symbolic Execution;Constraint Solving;Fuzzing;Environment Modeling},
  doi       = {10.1109/APSEC57359.2022.00045}
}


@inproceedings{KLEE,
  author    = {Cadar, Cristian and Dunbar, Daniel and Engler, Dawson},
  title     = {KLEE: unassisted and automatic generation of high-coverage tests for complex systems programs},
  year      = {2008},
  publisher = {USENIX Association},
  address   = {USA},
  abstract  = {We present a new symbolic execution tool, KLEE, capable of automatically generating tests that achieve high coverage on a diverse set of complex and environmentally-intensive programs. We used KLEE to thoroughly check all 89 stand-alone programs in the GNU COREUTILS utility suite, which form the core user-level environment installed on millions of Unix systems, and arguably are the single most heavily tested set of open-source programs in existence. KLEE-generated tests achieve high line coverage -- on average over 90\% per tool (median: over 94\%) -- and significantly beat the coverage of the developers' own hand-written test suite. When we did the same for 75 equivalent tools in the BUSYBOX embedded system suite, results were even better, including 100\% coverage on 31 of them.We also used KLEE as a bug finding tool, applying it to 452 applications (over 430K total lines of code), where it found 56 serious bugs, including three in COREUTILS that had been missed for over 15 years. Finally, we used KLEE to crosscheck purportedly identical BUSYBOX and COREUTILS utilities, finding functional correctness errors and a myriad of inconsistencies.},
  booktitle = {Proceedings of the 8th USENIX Conference on Operating Systems Design and Implementation},
  pages     = {209–224},
  numpages  = {16},
  location  = {San Diego, California},
  series    = {OSDI'08}
}

@inproceedings{CRETE,
  author    = {Chen, Bo and Havlicek, Christopher and Yang, Zhenkun and Cong, Kai and Kannavara, Raghudeep and Xie, Fei},
  editor    = {Russo, Alessandra and Sch{\"u}rr, Andy},
  title     = {CRETE: A Versatile Binary-Level Concolic Testing Framework},
  booktitle = {Fundamental Approaches to Software Engineering},
  year      = {2018},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {281--298},
  abstract  = {In this paper, we present crete, a versatile binary-level concolic testing framework, which features an open and highly extensible architecture allowing easy integration of concrete execution frontends and symbolic execution engine backends. crete's extensibility is rooted in its modular design where concrete and symbolic execution is loosely coupled only through standardized execution traces and test cases. The standardized execution traces are llvm-based, self-contained, and composable, providing succinct and sufficient information for symbolic execution engines to reproduce the concrete executions. We have implemented crete with klee as the symbolic execution engine and multiple concrete execution frontends such as qemu and 8051 Emulator. We have evaluated the effectiveness of crete on GNU Coreutils programs and TianoCore utility programs for UEFI BIOS. The evaluation of Coreutils programs shows that crete achieved comparable code coverage as klee directly analyzing the source code of Coreutils and generally outperformed angr. The evaluation of TianoCore utility programs found numerous exploitable bugs that were previously unreported.},
  isbn      = {978-3-319-89363-1}
}


@inproceedings{IMF-SIM,
  author    = {Wang, Shuai and Wu, Dinghao},
  booktitle = {2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  title     = {In-memory fuzzing for binary code similarity analysis},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {319-330},
  keywords  = {Binary codes;Tools;Runtime;Indexes;Syntactics;In-memory fuzzing;code similarity;reverse engineering;taint analysis},
  doi       = {10.1109/ASE.2017.8115645}
}

@inproceedings{Learch,
  author    = {He, Jingxuan and Sivanrupan, Gishor and Tsankov, Petar and Vechev, Martin},
  title     = {Learning to Explore Paths for Symbolic Execution},
  year      = {2021},
  isbn      = {9781450384544},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3460120.3484813},
  doi       = {10.1145/3460120.3484813},
  abstract  = {Symbolic execution is a powerful technique that can generate tests steering program execution into desired paths. However, the scalability of symbolic execution is often limited by path explosion, i.e., the number of symbolic states representing the paths under exploration quickly explodes as execution goes on. Therefore, the effectiveness of symbolic execution engines hinges on the ability to select and explore the right symbolic states.In this work, we propose a novel learning-based strategy, called Learch, able to effectively select promising states for symbolic execution to tackle the path explosion problem. Learch directly estimates the contribution of each state towards the goal of maximizing coverage within a time budget, as opposed to relying on manually crafted heuristics based on simple statistics as a crude proxy for the objective. Moreover, Learch leverages existing heuristics in training data generation and feature extraction, and can thus benefit from any new expert-designed heuristics. We instantiated Learch in KLEE, a widely adopted symbolic execution engine. We evaluated Learch on a diverse set of programs, showing that Learch is practically effective: it covers more code and detects more security violations than existing manual heuristics, as well as combinations of those heuristics. We also show that using tests generated by Learch as initial fuzzing seeds enables the popular fuzzer AFL to find more paths and security violations.},
  booktitle = {Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security},
  pages     = {2526–2540},
  numpages  = {15},
  keywords  = {fuzzing, machine learning, program testing, symbolic execution},
  location  = {Virtual Event, Republic of Korea},
  series    = {CCS '21}
}

@article{10.1145/2345156.2254088,
  author     = {Kuznetsov, Volodymyr and Kinder, Johannes and Bucur, Stefan and Candea, George},
  title      = {Efficient state merging in symbolic execution},
  year       = {2012},
  issue_date = {June 2012},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {47},
  number     = {6},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/2345156.2254088},
  doi        = {10.1145/2345156.2254088},
  abstract   = {Symbolic execution has proven to be a practical technique for building automated test case generation and bug finding tools. Nevertheless, due to state explosion, these tools still struggle to achieve scalability. Given a program, one way to reduce the number of states that the tools need to explore is to merge states obtained on different paths. Alas, doing so increases the size of symbolic path conditions (thereby stressing the underlying constraint solver) and interferes with optimizations of the exploration process (also referred to as search strategies). The net effect is that state merging may actually lower performance rather than increase it.We present a way to automatically choose when and how to merge states such that the performance of symbolic execution is significantly increased. First, we present query count estimation, a method for statically estimating the impact that each symbolic variable has on solver queries that follow a potential merge point; states are then merged only when doing so promises to be advantageous. Second, we present dynamic state merging, a technique for merging states that interacts favorably with search strategies in automated test case generation and bug finding tools.Experiments on the 96 GNU Coreutils show that our approach consistently achieves several orders of magnitude speedup over previously published results. Our code and experimental data are publicly available at http://cloud9.epfl.ch.},
  journal    = {SIGPLAN Not.},
  month      = {jun},
  pages      = {193–204},
  numpages   = {12},
  keywords   = {verification, testing, symbolic execution, state merging, bounded software model checking}
}

@inproceedings{Cloud9,
  author    = {Kuznetsov, Volodymyr and Kinder, Johannes and Bucur, Stefan and Candea, George},
  title     = {Efficient state merging in symbolic execution},
  year      = {2012},
  isbn      = {9781450312059},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2254064.2254088},
  doi       = {10.1145/2254064.2254088},
  abstract  = {Symbolic execution has proven to be a practical technique for building automated test case generation and bug finding tools. Nevertheless, due to state explosion, these tools still struggle to achieve scalability. Given a program, one way to reduce the number of states that the tools need to explore is to merge states obtained on different paths. Alas, doing so increases the size of symbolic path conditions (thereby stressing the underlying constraint solver) and interferes with optimizations of the exploration process (also referred to as search strategies). The net effect is that state merging may actually lower performance rather than increase it.We present a way to automatically choose when and how to merge states such that the performance of symbolic execution is significantly increased. First, we present query count estimation, a method for statically estimating the impact that each symbolic variable has on solver queries that follow a potential merge point; states are then merged only when doing so promises to be advantageous. Second, we present dynamic state merging, a technique for merging states that interacts favorably with search strategies in automated test case generation and bug finding tools.Experiments on the 96 GNU Coreutils show that our approach consistently achieves several orders of magnitude speedup over previously published results. Our code and experimental data are publicly available at http://cloud9.epfl.ch.},
  booktitle = {Proceedings of the 33rd ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages     = {193–204},
  numpages  = {12},
  keywords  = {verification, testing, symbolic execution, state merging, bounded software model checking},
  location  = {Beijing, China},
  series    = {PLDI '12}
}
